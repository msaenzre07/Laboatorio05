{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsEsGEADEsqzSuaXuphmQe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msaenzre07/Laboratorio05-Python/blob/master/lab_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando paquetes"
      ],
      "metadata": {
        "id": "QOdvMsmQmIA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy matplotlib seaborn scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBNcfDWfmK7h",
        "outputId": "64b6b565-34e7-4b45-ac74-81f3eadc975a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (0.12.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importando librerías"
      ],
      "metadata": {
        "id": "s0L7TRxAmMcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xlrd \n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.impute import SimpleImputer\n"
      ],
      "metadata": {
        "id": "RVKAMOagmYhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sección nueva"
      ],
      "metadata": {
        "id": "FUUR8KbfnN8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Carga de datos"
      ],
      "metadata": {
        "id": "bFzV0oUtoyQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# cargar datos\n",
        "indicadores_pais = pd.read_excel('Indice-de-paises.xlsx', sheet_name='indicadores_pais')\n",
        "indice_felicidad = pd.read_excel('Indice-de-paises.xlsx', sheet_name='indice_felicidad')\n",
        "\n",
        "# unir los dos datasets\n",
        "df = pd.merge(indicadores_pais, indice_felicidad, on='Country', how='left')"
      ],
      "metadata": {
        "id": "gQWSLxQBpZX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dimensiones del conjunto de datos\n",
        "print(df.shape)\n",
        "\n",
        "# tipos de datos de cada columna\n",
        "print(df.dtypes)\n"
      ],
      "metadata": {
        "id": "PbPxfHR1pf-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verificar si hay valores nulos\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "HBFif0x0pigq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Existencia valores atipicos\n",
        "data.boxplot(column=['Population', 'Area (sq. mi.)', 'Pop. Density (per sq. mi.)', 'Net migration', \n",
        "                     'Infant mortality (per 1000 births)', 'GDP ($ per capita)', 'Literacy (%)', \n",
        "                     'Phones (per 1000)', 'Arable (%)', 'Crops (%)', 'Other (%)', 'Climate', \n",
        "                     'Birthrate', 'Deathrate', 'Agriculture', 'Industry', 'Service', 'Happiness Rank', \n",
        "                     'Happiness Score', 'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', \n",
        "                     'Freedom', 'Trust (Government Corruption)', 'Generosity', 'Dystopia Residual'])\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-Bpzd1_YpoeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.hist(column=['Population', 'Area (sq. mi.)', 'Pop. Density (per sq. mi.)', 'Net migration', \n",
        "                  'Infant mortality (per 1000 births)', 'GDP ($ per capita)', 'Literacy (%)', \n",
        "                  'Phones (per 1000)', 'Arable (%)', 'Crops (%)', 'Other (%)', 'Climate', \n",
        "                  'Birthrate', 'Deathrate', 'Agriculture', 'Industry', 'Service', 'Happiness Rank', \n",
        "                  'Happiness Score', 'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', \n",
        "                  'Freedom', 'Trust (Government Corruption)', 'Generosity', 'Dystopia Residual'],\n",
        "           figsize=(20,20))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aH0LQYbMqUme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reemplazar los valores atípicos y nulos en las columnas numéricas, podemos crear una función que reemplaza los valores por la media o la mediana\n",
        "def replace_outliers(data, column, method='median', threshold=3):\n",
        "    \"\"\"\n",
        "    Reemplaza los valores atípicos de una columna numérica en un DataFrame con la media o la mediana.\n",
        "    \n",
        "    data: DataFrame\n",
        "        El DataFrame que contiene la columna a procesar.\n",
        "        \n",
        "    column: str\n",
        "        El nombre de la columna a procesar.\n",
        "        \n",
        "    method: str\n",
        "        La medida estadística a utilizar para reemplazar los valores atípicos. Puede ser 'mean' o 'median'.\n",
        "        \n",
        "    threshold: int\n",
        "        El umbral para detectar valores atípicos. Los valores más grandes o más pequeños que el umbral son tratados como valores atípicos.\n",
        "    \"\"\"\n",
        "    if method == 'mean':\n",
        "        value = data[column].mean()\n",
        "    elif method == 'median':\n",
        "        value = data[column].median()\n",
        "    else:\n",
        "        raise ValueError('Método no válido. Debe ser \"mean\" o \"\n"
      ],
      "metadata": {
        "id": "TwQ9sZa_qVjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reemplazar por el valor promedio de la región a la que pertenece el país que contiene el NA"
      ],
      "metadata": {
        "id": "7cjUHOrqrWsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Diccionario que contiene las regiones y sus promedios de felicidad\n",
        "region_avg = data.groupby('Region')[['Happiness Rank', 'Happiness Score']].mean().to_dict()\n",
        "\n",
        "# Función para reemplazar los valores nulos por el promedio de la región correspondiente\n",
        "def replace_nulls(data, column):\n",
        "    for index, row in data.iterrows():\n",
        "        if pd.isnull(row[column]):\n",
        "            region = row['Region']\n",
        "            region_mean = region_avg[column][region]\n",
        "            data.at[index, column] = region_mean\n",
        "    return data\n",
        "\n",
        "# Reemplazar los valores nulos en \"Happiness Rank\" y \"Happiness Score\" por el promedio de la región correspondiente\n",
        "data = replace_nulls(data, 'Happiness Rank')\n",
        "data = replace_nulls(data, 'Happiness Score')\n",
        "\n",
        "# Imprimir el conjunto de datos actualizado\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "4lGed2AcqxhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#convertir la columna country a fila\n"
      ],
      "metadata": {
        "id": "yB7dYLlPr3WV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Convertir la columna \"Country\" en una fila utilizando la función melt()\n",
        "data = pd.melt(data, id_vars=['Country', 'Region'], var_name='Indicator')\n",
        "\n",
        "# Pivoteo de datos para que los indicadores sean las columnas\n",
        "data = data.pivot(index=['Country', 'Region'], columns='Indicator', values='value').reset_index()\n",
        "\n",
        "# Eliminar la columna \"Country\" ya que ahora es el índice del conjunto de datos\n",
        "data = data.drop(columns=['Country'])\n",
        "\n",
        "# Normalizar los datos utilizando la técnica de estandarización\n",
        "scaler = StandardScaler()\n",
        "data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
        "\n",
        "# Imprimir los primeros 5 registros del conjunto de datos actualizado\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "RaKPtAU5r7A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la matriz de correlación entre las diferentes variables\n",
        "corr_matrix = data.corr()\n",
        "\n",
        "# Imprimir la matriz de correlación\n",
        "print(corr_matrix)\n"
      ],
      "metadata": {
        "id": "jjUiZDwOsXHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tecnica ACP"
      ],
      "metadata": {
        "id": "mgBr_7xitHoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convertir la columna \"Country\" en una fila utilizando la función melt()\n",
        "data = pd.melt(data, id_vars=['Country', 'Region'], var_name='Indicator')\n",
        "\n",
        "# Pivoteo de datos para que los indicadores sean las columnas\n",
        "data = data.pivot(index=['Country', 'Region'], columns='Indicator', values='value').reset_index()\n",
        "\n",
        "# Eliminar la columna \"Country\" ya que ahora es el índice del conjunto de datos\n",
        "data = data.drop(columns=['Country'])\n",
        "\n",
        "# Normalizar los datos utilizando la técnica de estandarización\n",
        "scaler = StandardScaler()\n",
        "data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
        "\n",
        "# Imprimir los primeros 5 registros del conjunto de datos actualizado\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "wdQz8wl8sXO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cantidad CP para formar nuevo dataset"
      ],
      "metadata": {
        "id": "pyYPVqgxtSDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calcular la varianza explicada por cada componente principal\n",
        "variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Graficar la varianza explicada por cada componente principal\n",
        "plt.plot(range(1, len(variance_ratio) + 1), variance_ratio, marker='o')\n",
        "plt.xlabel('Número de Componentes Principales')\n",
        "plt.ylabel('Varianza Explicada')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "azj0ppDctYsp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}